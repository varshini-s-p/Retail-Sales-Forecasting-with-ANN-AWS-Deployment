{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b618fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165a3245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday_x', 'Temperature',\n",
      "       'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4',\n",
      "       'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday_y', 'Type', 'Size'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Load Cleaned Data\n",
    "df = pd.read_csv('../data/processed_data/cleaned_data.csv')\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f88564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data\n",
    "df = pd.read_csv('../data/processed_data/cleaned_data.csv')\n",
    "\n",
    "# Drop non-relevant or duplicate columns\n",
    "df = df.drop(columns=['Date'])\n",
    "\n",
    "# One-hot encode categorical columns if not already encoded\n",
    "df = pd.get_dummies(df, columns=['Type'], drop_first=True)\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('Weekly_Sales', axis=1)\n",
    "y = df['Weekly_Sales']\n",
    "\n",
    "# Normalize features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b2af60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store             int64\n",
      "Dept              int64\n",
      "IsHoliday_x        bool\n",
      "Temperature     float64\n",
      "Fuel_Price      float64\n",
      "MarkDown1       float64\n",
      "MarkDown2       float64\n",
      "MarkDown3       float64\n",
      "MarkDown4       float64\n",
      "MarkDown5       float64\n",
      "CPI             float64\n",
      "Unemployment    float64\n",
      "IsHoliday_y        bool\n",
      "Size              int64\n",
      "Type_B             bool\n",
      "Type_C             bool\n",
      "dtype: object\n",
      "   Store  Dept  IsHoliday_x  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
      "0      1     1        False        42.31       2.572        0.0        0.0   \n",
      "1      1     1         True        38.51       2.548        0.0        0.0   \n",
      "2      1     1        False        39.93       2.514        0.0        0.0   \n",
      "3      1     1        False        46.63       2.561        0.0        0.0   \n",
      "4      1     1        False        46.50       2.625        0.0        0.0   \n",
      "\n",
      "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday_y  \\\n",
      "0        0.0        0.0        0.0  211.096358         8.106        False   \n",
      "1        0.0        0.0        0.0  211.242170         8.106         True   \n",
      "2        0.0        0.0        0.0  211.289143         8.106        False   \n",
      "3        0.0        0.0        0.0  211.319643         8.106        False   \n",
      "4        0.0        0.0        0.0  211.350143         8.106        False   \n",
      "\n",
      "     Size  Type_B  Type_C  \n",
      "0  151315   False   False  \n",
      "1  151315   False   False  \n",
      "2  151315   False   False  \n",
      "3  151315   False   False  \n",
      "4  151315   False   False  \n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes)\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ae0d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the ANN model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))  # regression output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247ef369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df4a439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 535237120.0000 - mae: 14804.5596 - val_loss: 474974400.0000 - val_mae: 14598.3164\n",
      "Epoch 2/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 459872192.0000 - mae: 14495.2100 - val_loss: 470590656.0000 - val_mae: 14501.7422\n",
      "Epoch 3/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 458616544.0000 - mae: 14448.1250 - val_loss: 462769152.0000 - val_mae: 14131.8184\n",
      "Epoch 4/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 450200832.0000 - mae: 14208.7705 - val_loss: 447548768.0000 - val_mae: 14087.9189\n",
      "Epoch 5/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 443621056.0000 - mae: 13879.1660 - val_loss: 432489696.0000 - val_mae: 13563.6973\n",
      "Epoch 6/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 421537824.0000 - mae: 13475.3545 - val_loss: 419911744.0000 - val_mae: 13381.9268\n",
      "Epoch 7/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 408315680.0000 - mae: 13177.1357 - val_loss: 404436736.0000 - val_mae: 12603.2188\n",
      "Epoch 8/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 401898176.0000 - mae: 12626.6846 - val_loss: 393103680.0000 - val_mae: 12171.9785\n",
      "Epoch 9/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 393031232.0000 - mae: 12291.0010 - val_loss: 389588480.0000 - val_mae: 11948.7344\n",
      "Epoch 10/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 382663328.0000 - mae: 12090.5078 - val_loss: 386980928.0000 - val_mae: 12076.4961\n",
      "Epoch 11/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 386942624.0000 - mae: 12096.0479 - val_loss: 385642176.0000 - val_mae: 11971.8857\n",
      "Epoch 12/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 381655424.0000 - mae: 12007.3594 - val_loss: 384086944.0000 - val_mae: 11974.4854\n",
      "Epoch 13/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 378939456.0000 - mae: 12013.3232 - val_loss: 382998656.0000 - val_mae: 11973.3291\n",
      "Epoch 14/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 376444896.0000 - mae: 11965.5703 - val_loss: 382432416.0000 - val_mae: 11840.8652\n",
      "Epoch 15/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 375260672.0000 - mae: 11882.6416 - val_loss: 381303008.0000 - val_mae: 12064.7695\n",
      "Epoch 16/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 383487520.0000 - mae: 11971.8535 - val_loss: 381330624.0000 - val_mae: 11709.7246\n",
      "Epoch 17/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 374408160.0000 - mae: 11849.5205 - val_loss: 380074624.0000 - val_mae: 12069.0029\n",
      "Epoch 18/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 374936096.0000 - mae: 11871.1572 - val_loss: 379310048.0000 - val_mae: 11874.4814\n",
      "Epoch 19/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 375103232.0000 - mae: 11926.6299 - val_loss: 378906688.0000 - val_mae: 11819.7695\n",
      "Epoch 20/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 374770688.0000 - mae: 11879.0518 - val_loss: 379188640.0000 - val_mae: 11694.0264\n",
      "Epoch 21/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 371093984.0000 - mae: 11860.1865 - val_loss: 377720608.0000 - val_mae: 11898.7471\n",
      "Epoch 22/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 368947840.0000 - mae: 11808.1289 - val_loss: 377131584.0000 - val_mae: 11848.0166\n",
      "Epoch 23/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 370526688.0000 - mae: 11842.0195 - val_loss: 376612832.0000 - val_mae: 11971.9893\n",
      "Epoch 24/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 370988320.0000 - mae: 11819.0186 - val_loss: 375855488.0000 - val_mae: 11863.5703\n",
      "Epoch 25/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 371670656.0000 - mae: 11774.2803 - val_loss: 375204096.0000 - val_mae: 11937.1113\n",
      "Epoch 26/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 371758976.0000 - mae: 11830.7725 - val_loss: 374403104.0000 - val_mae: 11798.4727\n",
      "Epoch 27/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 365924032.0000 - mae: 11829.2158 - val_loss: 373851872.0000 - val_mae: 11785.9189\n",
      "Epoch 28/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 366221952.0000 - mae: 11750.2432 - val_loss: 373678368.0000 - val_mae: 11597.9170\n",
      "Epoch 29/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 368908672.0000 - mae: 11768.8564 - val_loss: 372361056.0000 - val_mae: 11682.9893\n",
      "Epoch 30/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 365681440.0000 - mae: 11767.4258 - val_loss: 372322496.0000 - val_mae: 11526.3330\n",
      "Epoch 31/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 372085888.0000 - mae: 11754.8486 - val_loss: 370849920.0000 - val_mae: 11747.8340\n",
      "Epoch 32/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 361972960.0000 - mae: 11671.6924 - val_loss: 369994144.0000 - val_mae: 11760.4082\n",
      "Epoch 33/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 368227296.0000 - mae: 11705.4170 - val_loss: 369625664.0000 - val_mae: 11556.6260\n",
      "Epoch 34/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 366796480.0000 - mae: 11728.0371 - val_loss: 368393344.0000 - val_mae: 11677.2998\n",
      "Epoch 35/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 364076800.0000 - mae: 11703.0918 - val_loss: 369171040.0000 - val_mae: 11367.9590\n",
      "Epoch 36/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 365319264.0000 - mae: 11675.9492 - val_loss: 366665088.0000 - val_mae: 11593.5039\n",
      "Epoch 37/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 358247936.0000 - mae: 11633.8828 - val_loss: 365397984.0000 - val_mae: 11918.8711\n",
      "Epoch 38/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 363103072.0000 - mae: 11625.3398 - val_loss: 364592992.0000 - val_mae: 11589.7891\n",
      "Epoch 39/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - loss: 355256480.0000 - mae: 11631.7930 - val_loss: 362437888.0000 - val_mae: 11721.4961\n",
      "Epoch 40/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 361910880.0000 - mae: 11625.6846 - val_loss: 360940992.0000 - val_mae: 11670.3555\n",
      "Epoch 41/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 359605472.0000 - mae: 11608.8467 - val_loss: 359435520.0000 - val_mae: 11803.4697\n",
      "Epoch 42/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 357041952.0000 - mae: 11556.3848 - val_loss: 359305792.0000 - val_mae: 11269.3047\n",
      "Epoch 43/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 355757888.0000 - mae: 11510.9863 - val_loss: 355727520.0000 - val_mae: 11483.6084\n",
      "Epoch 44/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 345316288.0000 - mae: 11498.6240 - val_loss: 353430912.0000 - val_mae: 11487.4873\n",
      "Epoch 45/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 348858048.0000 - mae: 11443.1338 - val_loss: 351587680.0000 - val_mae: 11485.6133\n",
      "Epoch 46/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 355796320.0000 - mae: 11488.0508 - val_loss: 349114880.0000 - val_mae: 11361.6973\n",
      "Epoch 47/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 341391808.0000 - mae: 11354.0752 - val_loss: 347126720.0000 - val_mae: 11441.9170\n",
      "Epoch 48/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 345997120.0000 - mae: 11414.1504 - val_loss: 344337376.0000 - val_mae: 11364.7061\n",
      "Epoch 49/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 346824736.0000 - mae: 11338.7158 - val_loss: 342570464.0000 - val_mae: 11262.4600\n",
      "Epoch 50/50\n",
      "\u001b[1m8432/8432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - loss: 338174656.0000 - mae: 11279.8721 - val_loss: 339692832.0000 - val_mae: 11183.8867\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e5cb547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2635/2635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 628us/step\n",
      "MAE: 11170.21\n",
      "MSE: 337938925.51\n",
      "RMSE: 18383.12\n",
      "R^2 Score: 0.35\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the Model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d24ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dump' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/ann_sales_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Save the scaler for future use\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdump\u001b[49m(scaler, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/minmax_scaler.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dump' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('../models/ann_sales_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b00df2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/scaler.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, '../models/scaler.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
